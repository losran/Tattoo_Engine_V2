import streamlit as st
import random
import time
from openai import OpenAI
from engine_manager import init_data, render_sidebar
from style_manager import apply_pro_style

# ===========================
# 1. åˆå§‹åŒ–
# ===========================
st.set_page_config(layout="wide", page_title="Graphic Lab")
apply_pro_style()
render_sidebar()
init_data()

client = None
if "DEEPSEEK_KEY" in st.secrets:
    try:
        client = OpenAI(api_key=st.secrets["DEEPSEEK_KEY"], base_url="https://api.deepseek.com")
    except:
        pass

# ===========================
# 2. è¾…åŠ©å‡½æ•°
# ===========================
def smart_pick(category):
    db = st.session_state.get("db_all", {})
    items = db.get(category, [])
    if items: return random.choice(items)
    return ""

def assemble_skeleton(user_input):
    """ç§’çº§ç»„è£…éª¨æ¶"""
    subject = user_input if user_input.strip() else smart_pick("Subject")
    
    parts = [
        subject,
        f"{smart_pick('StyleSystem')} style",
        f"{smart_pick('Technique')} technique",
        f"{smart_pick('Color')} palette",
        f"{smart_pick('Texture')} texture",
        f"{smart_pick('Composition')} composition",
        smart_pick('Action'),
        f"{smart_pick('Mood')} vibe"
    ]
    
    if random.random() > 0.6:
        parts.append(f"with {smart_pick('Accent')} details")
        
    return ", ".join([p for p in parts if p and " style" not in p[:1]])

# ===========================
# 3. ç•Œé¢äº¤äº’
# ===========================
st.title("Graphic Lab")
st.caption("Precision Assembly & AI Polish")

c1, c2 = st.columns([3, 1])
with c1:
    user_in = st.text_input("Core Subject", placeholder="Leave empty for Blind Box mode...")
with c2:
    qty = st.number_input("Batch Size", 1, 8, 4)

# ===========================
# 4. æ‰§è¡Œé€»è¾‘ (ä¿®å¤æŠ–åŠ¨)
# ===========================
if st.button("Generate", type="primary", use_container_width=True):
    
    st.session_state.final_solutions = [] 
    placeholders = []   
    skeletons = []      
    
    # --- ç¬¬ä¸€é˜¶æ®µï¼šç§’å‡ºéª¨æ¶ (UI ç»Ÿä¸€åŒ–) ---
    for i in range(qty):
        idx = i + 1
        ph = st.empty()
        placeholders.append(ph)
        
        sk = assemble_skeleton(user_in)
        skeletons.append(sk)
        
        # ğŸŸ¢ ä¿®å¤ç‚¹ï¼šä¸å†ç”¨ HTML divï¼Œè€Œæ˜¯ç›´æ¥ç”¨åŸç”Ÿ container
        # è¿™æ ·å®ƒçš„è¾¹æ¡†å’Œå†…è¾¹è·å°±å’Œä¸‹é¢â€œç”Ÿæˆä¸­â€çš„çŠ¶æ€å®Œå…¨ä¸€è‡´äº†
        with ph.container(border=True):
            st.markdown(f"**Option {idx}:** {sk}")
            st.caption("âœ¨ AI is thinking...") 
    
    # --- ç¬¬äºŒé˜¶æ®µï¼šæµå¼æ¶¦è‰² ---
    sys_prompt = "You are a tattoo art director. Refine the keywords into a high-quality Midjourney prompt."
    final_results = []

    for i, sk in enumerate(skeletons):
        idx = i + 1
        ph = placeholders[i]
        
        user_prompt = f"""
        Raw Keywords: {sk}
        Task: Write a descriptive Midjourney prompt (40-60 words).
        Start EXACTLY with "**Option {idx}:**".
        """
        
        full_response = ""
        
        try:
            # æ¸…ç©ºåŸæ¥çš„
            ph.empty()
            
            # ğŸŸ¢ ä¿æŒä¸€è‡´ï¼šç»§ç»­ä½¿ç”¨ container(border=True)
            with ph.container(border=True):
                if client:
                    stream = client.chat.completions.create(
                        model="deepseek-chat",
                        messages=[{"role": "system", "content": sys_prompt},{"role": "user", "content": user_prompt}],
                        temperature=0.9,
                        stream=True 
                    )
                    full_response = st.write_stream(stream)
                    if not full_response.startswith("**"):
                        full_response = f"**Option {idx}:** {full_response}"
                else:
                    # æ—  Key æ¨¡æ‹Ÿ
                    dummy = f"**Option {idx}:** {sk} (Offline Mode)"
                    def dummy_stream():
                        for w in dummy.split(" "):
                            yield w + " "
                            time.sleep(0.05)
                    full_response = st.write_stream(dummy_stream)

        except Exception as e:
            # æŠ¥é”™æ—¶çš„æ˜¾ç¤º
            ph.empty()
            with ph.container(border=True):
                err_msg = str(e)
                note = "Connection Error"
                if "401" in err_msg: note = "Invalid API Key"
                
                # çº¢è‰²è­¦å‘Šæ–‡å­—
                st.markdown(f"**Option {idx}:** {sk}")
                st.markdown(f":red[âš ï¸ {note} - Using Raw Data]")
                
                full_response = f"**Option {idx}:** {sk} ({note})"

        final_results.append(full_response)

    st.session_state.final_solutions = final_results
    st.rerun()

# ===========================
# 5. ç»“æœå±•ç¤º
# ===========================
if "final_solutions" in st.session_state and st.session_state.final_solutions:
    st.markdown("---")
    st.subheader("Final Output")
    
    for sol in st.session_state.final_solutions:
        # ğŸŸ¢ æœ€ç»ˆå±•ç¤ºä¹Ÿç”¨åŸç”Ÿ containerï¼Œå½»åº•ç»Ÿä¸€è§†è§‰
        with st.container(border=True):
            st.markdown(sol)
        
    c_send, c_clear = st.columns([3, 1])
    
    with c_send:
        if st.button("Send to Automation", type="primary", use_container_width=True):
            st.switch_page("pages/03_ğŸš€_Automation.py")
            
    with c_clear:
        if st.button("Clear Results", use_container_width=True):
            st.session_state.final_solutions = []
            st.rerun()
