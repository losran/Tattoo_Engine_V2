import streamlit as st
import sys
import os
import random
import time
from openai import OpenAI

# ===========================
# 0. è·¯å¾„ä¿®å¤ (ç¡®ä¿èƒ½æ‰¾åˆ°æ ¹ç›®å½•æ¨¡å—)
# ===========================
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.abspath(os.path.join(current_dir, '..'))
if parent_dir not in sys.path:
    sys.path.append(parent_dir)

from engine_manager import init_data, render_sidebar
from style_manager import apply_pro_style

# ===========================
# 1. åˆå§‹åŒ–
# ===========================
st.set_page_config(layout="wide", page_title="Graphic Lab")
apply_pro_style()
render_sidebar()
init_data()

client = None
if "DEEPSEEK_KEY" in st.secrets:
    try:
        client = OpenAI(api_key=st.secrets["DEEPSEEK_KEY"], base_url="https://api.deepseek.com")
    except:
        pass

# ===========================
# 2. æ ¸å¿ƒå¼•æ“ (é›¶ä»¶ç»„è£…)
# ===========================
def smart_pick(category):
    db = st.session_state.get("db_all", {})
    items = db.get(category, [])
    if items: return random.choice(items)
    return ""

def assemble_skeleton(user_input):
    """ç§’çº§ç»„è£…éª¨æ¶ - 100% è¿˜åŸä½ çš„é›¶ä»¶é€»è¾‘"""
    subject = user_input if user_input.strip() else smart_pick("Subject")
    
    parts = [
        subject,
        f"{smart_pick('StyleSystem')} style",
        f"{smart_pick('Technique')} technique",
        f"{smart_pick('Color')} palette",
        f"{smart_pick('Texture')} texture",
        f"{smart_pick('Composition')} composition",
        smart_pick('Action'),
        f"{smart_pick('Mood')} vibe"
    ]
    
    # æ··æ²Œç‚¹ç¼€
    if random.random() > 0.6:
        parts.append(f"with {smart_pick('Accent')} details")
        
    return ", ".join([p for p in parts if p and " style" not in p[:1]])

# ===========================
# 3. ç•Œé¢äº¤äº’
# ===========================
st.markdown("## ğŸ¨ Graphic Lab")
st.caption("Auto-Assembly -> AI Polish -> Batch Handoff")

c1, c2 = st.columns([3, 1])
with c1:
    user_in = st.text_input("Core Subject", placeholder="Leave empty for Blind Box mode...", label_visibility="collapsed")
with c2:
    qty = st.number_input("Batch Size", 1, 8, 4, label_visibility="collapsed")

# ===========================
# 4. æ‰§è¡Œé€»è¾‘ (AI æ¶¦è‰²å ¡å’)
# ===========================
if st.button("Generate", type="primary", use_container_width=True):
    
    st.session_state.graphic_solutions = [] 
    placeholders = []   
    skeletons = []      
    
    # --- ç¬¬ä¸€é˜¶æ®µï¼šç§’å‡ºéª¨æ¶ ---
    for i in range(qty):
        idx = i + 1
        ph = st.empty()
        placeholders.append(ph)
        
        sk = assemble_skeleton(user_in)
        skeletons.append(sk)
        
        with ph.container(border=True):
            st.markdown(f"**æ–¹æ¡ˆ{idx}ï¼š** {sk}")
            st.caption("âœ¨ èµ„æ·±ç­–å±•äººæ­£åœ¨æ¶¦è‰²æ–‡æ¡ˆ...") 
    
    # --- ç¬¬äºŒé˜¶æ®µï¼šæµå¼æ¶¦è‰² (è¿˜åŸè°ƒæ•™é€»è¾‘) ---
    # ğŸ”´ æ ¸å¿ƒä¿®æ”¹ï¼šè¿˜åŸä½ çš„ sys_prompt
    sys_prompt = "ä½ æ˜¯ä¸€ä½èµ„æ·±åˆºé’ç­–å±•äººã€‚è¯·å°†æä¾›çš„å…³é”®è¯ç»„åˆæ¶¦è‰²ä¸ºæå…·è‰ºæœ¯æ„Ÿçš„çº¹èº«æè¿°ã€‚æ¯æ®µå¿…é¡»å‡ºç°'çº¹èº«'äºŒå­—ã€‚"
    
    final_results = []

    for i, sk in enumerate(skeletons):
        idx = i + 1
        ph = placeholders[i]
        
        # ğŸ”´ æ ¸å¿ƒä¿®æ”¹ï¼šè¿˜åŸä½ çš„ user_prompt (å«é”šç‚¹ä¸å­—æ•°è¦æ±‚)
        user_prompt = f"""
        ã€åŸå§‹éª¨æ¶ã€‘ï¼š{sk}
        
        ã€æŒ‡ä»¤ã€‘ï¼š
        1. å¿…é¡»ä¸¥æ ¼ä¿ç•™éª¨æ¶ä¸­çš„é£æ ¼ã€é¢œè‰²ã€éƒ¨ä½ç­‰å…³é”®ä¿¡æ¯ã€‚
        2. å¿…é¡»ä¸¥æ ¼ä»¥ "**æ–¹æ¡ˆ{idx}ï¼š**" å¼€å¤´ (åŒæ˜Ÿå·+å…¨è§’å†’å·)ã€‚è¿™æ˜¯è‡ªåŠ¨åŒ–è¯†åˆ«çš„é”šç‚¹ã€‚
        3. è¾“å‡ºä¸€æ®µ 50-80 å­—çš„å®Œæ•´è§†è§‰æè¿°ã€‚
        """
        
        full_response = ""
        
        try:
            ph.empty()
            with ph.container(border=True):
                if client:
                    stream = client.chat.completions.create(
                        model="deepseek-chat",
                        messages=[
                            {"role": "system", "content": sys_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        temperature=0.85, # è¿˜åŸé«˜é‡‡æ ·ç‡
                        stream=True 
                    )
                    full_response = st.write_stream(stream)
                    # å¼ºæ ¡éªŒé”šç‚¹
                    if not full_response.startswith("**æ–¹æ¡ˆ"):
                        full_response = f"**æ–¹æ¡ˆ{idx}ï¼š** {full_response}"
                else:
                    # ç¦»çº¿æ¨¡æ‹Ÿ
                    dummy = f"**æ–¹æ¡ˆ{idx}ï¼š** {sk} (AI Offline)"
                    def dummy_stream():
                        for w in dummy.split(" "):
                            yield w + " "
                            time.sleep(0.05)
                    full_response = st.write_stream(dummy_stream)

        except Exception as e:
            ph.empty()
            with ph.container(border=True):
                st.markdown(f"**æ–¹æ¡ˆ{idx}ï¼š** {sk}")
                st.markdown(f":red[âš ï¸ æ¶¦è‰²å¤±è´¥ - {str(e)}]")
                full_response = f"**æ–¹æ¡ˆ{idx}ï¼š** {sk}"

        final_results.append(full_response)

    st.session_state.graphic_solutions = final_results
    st.rerun()

# ===========================
# 5. ç»“æœå±•ç¤ºä¸å åŠ å‘é€
# ===========================
if "graphic_solutions" in st.session_state and st.session_state.graphic_solutions:
    st.markdown("---")
    st.subheader("ğŸ“¦ Ready for Automation")
    
    for sol in st.session_state.graphic_solutions:
        with st.container(border=True):
            st.markdown(sol)
        
    c_send, c_clear = st.columns([3, 1])
    
    with c_send:
        if st.button("ğŸš€ Send ALL to Automation Pipeline (å åŠ )", type="primary", use_container_width=True):
            if "global_queue" not in st.session_state:
                st.session_state.global_queue = []
            
            # å åŠ å‘é€é€»è¾‘
            st.session_state.global_queue.extend(st.session_state.graphic_solutions)
            
            st.toast(f"âœ… å·²æ·»åŠ  {len(st.session_state.graphic_solutions)} ç»„æ–¹æ¡ˆè‡³è‡ªåŠ¨åŒ–é˜Ÿåˆ—")
            time.sleep(0.8)
            # æ³¨æ„ï¼šè¯·ç¡®ä¿ä½ çš„è‡ªåŠ¨åŒ–æ–‡ä»¶åä¸æ­¤å¤„ä¸€è‡´
            st.switch_page("pages/03_ğŸš€_Automation.py")
            
    with c_clear:
        if st.button("ğŸ—‘ï¸ Clear Results", use_container_width=True):
            st.session_state.graphic_solutions = []
            st.rerun()
